- BackProp
	- http://www.hankcs.com/ml/back-propagation-neural-network.html
	- https://github.com/hankcs/neural_net/blob/master/bpnn.py
	- http://www.cnblogs.com/daniel-D/archive/2013/06/03/3116278.html
	- http://www.cnblogs.com/daniel-D/archive/2013/06/06/3121742.html
	- http://blog.csdn.net/pennyliang/article/details/6695355
	- http://hahack.com/reading/ann1/
	- http://hahack.com/reading/ann2/
	- http://www.inf.ufrgs.br/~engel/data/media/file/RNSF/bp-matlab.pdf
	- http://hagan.okstate.edu/nnd.html
	- http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf
	- http://mooc.guokr.com/note/16702/
	- https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/
	- http://blog.aloni.org/posts/backprop-with-tensorflow/
	- http://colah.github.io/posts/2015-08-Backprop/
	- http://outlace.com/Computational-Graph/
	- https://medium.com/@karpathy/yes-you-should-understand-backprop-e2f06eab496b
	- https://arxiv.org/abs/1606.04474
		- https://github.com/deepmind/learning-to-learn

- SyntheticGradients
	- https://arxiv.org/abs/1608.05343
	- https://www.zhihu.com/question/50188965
	- https://deepmind.com/blog/decoupled-neural-networks-using-synthetic-gradients/
	- http://deliprao.com/archives/187
	- https://medium.com/machine-learning-at-petiteprogrammer/3-ways-synthetic-gradients-will-revolutionize-deep-learning-f812ad1b8c0b
	- https://greydanus.github.io/2016/11/26/synthetic-gradients/
	- https://github.com/kbullaughey/dni-synthetic-gradients
	- https://github.com/macfergus/synthetic-gradient
	- https://arxiv.org/abs/1703.00522
	- http://iamtrask.github.io/2017/03/21/synthetic-gradients/

- BatchNormalization
	- http://arxiv.org/pdf/1502.03167v3.pdf
	- http://www.cnblogs.com/neopenx/p/5211969.html
	- http://blog.csdn.net/happynear/article/details/44238541
	- http://blog.csdn.net/hjimce/article/details/50866313
	- https://www.zhihu.com/question/38102762
	- http://meank.github.io/2015/10/04/papers/batch-normalization-e7-ae-80-e5-8d-95-e7-90-86-e8-a7-a3/
	- https://arxiv.org/abs/1603.09025
	- http://www.voidcn.com/blog/malefactor/article/p-5984256.html
	- http://www.voidcn.com/blog/malefactor/article/p-5995518.html
	- https://www.quora.com/Why-does-batch-normalization-help
	- https://gab41.lab41.org/batch-normalization-what-the-hey-d480039a9e3b
	- http://blog.smola.org/post/4110255196/real-simple-covariate-shift-correction
	- http://sifaka.cs.uiuc.edu/jiang4/domain_adaptation/survey/node8.html
	- http://www.jianshu.com/p/0312e04e4e83
	- http://blog.csdn.net/u012816943/article/details/51691868
	- https://kratzert.github.io/2016/02/12/understanding-the-gradient-flow-through-the-batch-normalization-layer.html
	- http://chuansong.me/n/466160351256
	- https://arxiv.org/abs/1607.06450
	- http://cthorey.github.io./backpropagation/
	- http://arxiv.org/abs/1602.07868
		- https://github.com/openai/weightnorm
	- http://arxiv.org/abs/1607.02488
	- http://arxiv.org/abs/1607.06011

	- http://andyljones.tumblr.com/post/110998971763/an-explanation-of-xavier-initialization
	- http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf
	- http://deepdish.io/2015/02/24/network-initialization/
	- http://chrischoy.github.io/research/neural-network-weight-initialization/
	- http://blog.csdn.net/tangwei2014/article/details/47091881
	- http://stats.stackexchange.com/questions/198840/cnn-xavier-weight-initialization
	- https://prateekvjoshi.com/2016/03/29/understanding-xavier-initialization-in-deep-neural-networks/
	- https://www.quora.com/What-are-good-initial-weights-in-a-neural-network
	- http://arxiv.org/abs/1511.06422
	- http://blog.csdn.net/qq_26898461/article/details/50996507
	- http://blog.csdn.net/shuzfan/article/details/51338178
	- http://blog.csdn.net/shuzfan/article/details/51347572
	- https://arxiv.org/abs/1312.6120
	- https://pillowlab.wordpress.com/2015/10/04/exact-solutions-to-the-nonlinear-dynamics-of-learning-in-deep-linear-neural-networks/
	- http://hjweide.github.io/orthogonal-initialization-in-convolutional-layers
	- http://arxiv.org/abs/1511.07289
	- http://image-net.org/challenges/posters/JKU_EN_RGB_Schwarz_poster.pdf
	- http://chuansong.me/n/472464751936
	- http://arxiv.org/abs/1505.00853
	- http://www.cnblogs.com/neopenx/p/4453161.html
	- https://arxiv.org/abs/1606.00305
	- http://arxiv.org/abs/1603.05201
	- https://arxiv.org/abs/1412.6558
	- http://arxiv.org/abs/1511.06856
	- http://arxiv.org/abs/1512.07030
	- http://arxiv.org/abs/1603.01431
	- https://www.acsu.buffalo.edu/~devansha/resources/normprop_slides_icml16.pdf
	- http://happynear.wang/2016/03/22/Normalization-Propagation/
	- http://www.jianshu.com/p/db35f7f8a593
	- http://arxiv.org/abs/1606.08415
	- http://www.bioinf.jku.at/publications/older/ch7.pdf
	- https://arxiv.org/abs/1610.06160
	- http://www.diva-portal.org/smash/get/diva2:955562/FULLTEXT01.pdf
	- https://arxiv.org/abs/1612.01452
	- https://github.com/cvjena/cnn-models
	- https://arxiv.org/abs/1701.07275
	- https://arxiv.org/abs/1611.04520
	- https://arxiv.org/abs/1702.03275
	- https://arxiv.org/abs/1702.05870
	- http://geek.csdn.net/news/detail/160906
	- https://arxiv.org/abs/1506.01186
	- http://nyus.joshuawise.com/batchnorm.pdf

- LRN
	- http://www.jianshu.com/p/c06aea337d5d
